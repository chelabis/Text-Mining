{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c0544a",
   "metadata": {},
   "source": [
    "# Text Mining Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a10112d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3dc451",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "### Using Amazon_Unlocked_Mobile dataset from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237509c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55057b9d",
   "metadata": {},
   "source": [
    "### Remove null value rows and rating=3 to prepare data for sentiment analysis(positive or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f666abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>I already had a phone with problems... I know ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>The charging port was loose. I got that solder...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Phone looks good but wouldn't stay charged, ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I originally was using the Samsung S2 Galaxy f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great product it came after two days...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name Brand Name   Price  \\\n",
       "0   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "5   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "6   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "7   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "8   \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "11  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "    Rating                                            Reviews  Review Votes  \\\n",
       "0        5  I feel so LUCKY to have found this used (phone...           1.0   \n",
       "1        4  nice phone, nice up grade from my pantach revu...           0.0   \n",
       "2        5                                       Very pleased           0.0   \n",
       "3        4  It works good but it goes slow sometimes but i...           0.0   \n",
       "4        4  Great phone to replace my lost phone. The only...           0.0   \n",
       "5        1  I already had a phone with problems... I know ...           1.0   \n",
       "6        2  The charging port was loose. I got that solder...           0.0   \n",
       "7        2  Phone looks good but wouldn't stay charged, ha...           0.0   \n",
       "8        5  I originally was using the Samsung S2 Galaxy f...           0.0   \n",
       "11       5  This is a great product it came after two days...           0.0   \n",
       "\n",
       "    Positively Rated  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  1  \n",
       "11                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)   # Drop any rwos with null value\n",
    "df = df[df['Rating'] != 3]   # Assume rating 3 is neutral and ignore considering that\n",
    "df['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)  # Create column for positive sentiment\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224cadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748269374249846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Positively Rated'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a6e19",
   "metadata": {},
   "source": [
    "#### It shows we have imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75e481",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "### Split the data to train and test set. Reviews assumed as input and Positively Rated is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44fdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4718b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entery:\n",
      "\n",
      " I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\n",
      "\n",
      "\n",
      "X_train shape:  (231202,)\n"
     ]
    }
   ],
   "source": [
    "X = df['Reviews']\n",
    "y = df['Positively Rated']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print('X_train first entery:\\n\\n', X_train[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0cb80",
   "metadata": {},
   "source": [
    "### Vectorize data to use classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec83d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afdce6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc7e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab list contains:  53271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '4h', 'adpaters', 'assembly', 'blasts', 'cashiers',\n",
       "       'condidtion', 'debit', 'domestic', 'estimates', 'flawlessy',\n",
       "       'gothrough', 'hui', 'irritating', 'lighting5', 'microcomputer',\n",
       "       'nigeria', 'p7_l00', 'poorer', 'quirkyness', 'responsibility',\n",
       "       'sens', 'sorrow', 'synch', 'trace', 'usvi', 'within3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Vocab list contains: ', len(vect.get_feature_names_out()))\n",
    "vect.get_feature_names_out()[::2000]     # Every 2000th feature of vocabluary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cabd7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<231202x53271 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6113585 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea690e9",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Using this model which is suitable for high dimentional data and binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e27c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6539263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000).fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274269e4",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "### Using roc area under the curve method to evaluate our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc0c0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb7c8b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9303790943660453\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(vect.transform(X_test))   # Predictions: using vectorized test data\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0458e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['mony' 'worst' 'false' 'horribly' 'dissatisfied' 'worthless'\n",
      " 'unsatisfied' 'junk' 'blacklist' 'garbage']\n",
      "\n",
      "Largest Coefs: \n",
      "['excelent' 'excelente' '4eeeks' 'efficient' 'excellent' 'loving'\n",
      " 'exelente' 'lovely' 'loves' 'mn8k2ll']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))      # Connected to negative reviews\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))    # Connected to positive reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aeb3c2",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32ec66",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9642be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65b6d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf vocab list contains:  18024\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df=5).fit(X_train)   # Vocab list with words that appear at least 5 times in the document.\n",
    "print('Tfidf vocab list contains: ', len(vect.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de84171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9279682537578712\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train_vectorized, y_train)\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5c7f8",
   "metadata": {},
   "source": [
    "#### Smallest Tfidf: List of words which Commonly appeared across all reviews, or only appeared rarely in very long reviews.\n",
    "#### Largest Tfidf: List of words which appeared frequently in a review, but did not appear commonly across all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bacb9461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Tfidf:\n",
      "['storageso' 'warmness' 'aggregration' 'commenter' 'pthalo' '1300' '34ghz'\n",
      " 'bridging' 'srgb' 'seizing']\n",
      "\n",
      "Largest Tfidf: \n",
      "['too' 'malo' 'true' 'bjvjjbkvjvj' 'satisfied' 'problems' 'satisfecho'\n",
      " 'malfunction' 'satisfactory' 'horrible']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest Tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest Tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76a78bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['not' 'worst' 'terrible' 'useless' 'waste' 'disappointed' 'poor' 'return'\n",
      " 'horrible' 'returning']\n",
      "\n",
      "Largest Coefs: \n",
      "['love' 'great' 'excellent' 'amazing' 'perfect' 'easy' 'perfectly'\n",
      " 'awesome' 'loves' 'best']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdec018",
   "metadata": {},
   "source": [
    "#### Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41bc3ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "X_pred = vect.transform(['not an issue, phone is working', 'an issue, phone is not working'])   # Sample input\n",
    "print(model.predict(X_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646ac28",
   "metadata": {},
   "source": [
    "#### The first sentence is classified as negative! Using n-grams to handle it.\n",
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a09486f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200192"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "len(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f138dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9674179850589075\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000).fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d628f59a",
   "metadata": {},
   "source": [
    "#### With bigrams auc of the model is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6c2549d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['no good' 'junk' 'worst' 'not good' 'horrible' 'terrible' 'not happy'\n",
      " 'not very' 'looks ok' 'garbage']\n",
      "\n",
      "Largest Coefs: \n",
      "['not bad' 'excelent' 'excelente' 'excellent' 'no problems' 'perfect'\n",
      " 'no issues' 'exelente' 'awesome' 'amazing']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcc516be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "X_pred = vect.transform(['not an issue, phone is working', 'an issue, phone is not working'])   # Sample input\n",
    "print(model.predict(X_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195c8a2",
   "metadata": {},
   "source": [
    "#### The problem is solved!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
